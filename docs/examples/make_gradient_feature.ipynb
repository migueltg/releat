{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Feature\n",
    "\n",
    "Example of how a feature is built. This notebook goes through each step in the `build_features_by_dt` function (and its components) in `releat/data/pipeline.py` script\n",
    "\n",
    "## PREREQUISITE - Download tick data\n",
    "\n",
    "Before running this notebook, download tick data from brokers by running the following command from within the docker container: \n",
    "\n",
    "`/.venv/bin/python /workspaces/releat/workflows/download_mt5_data.py`\n",
    "\n",
    "Alternatively, you can run it from your local terminal and execute on your docker container, replace `<container-name>` with the name of the container, which should either be `releat` or `releat-dc` depending on how you set it up:\n",
    "\n",
    "`docker exec -it <container-name> /.venv/bin/python /workspaces/releat/workflows/download_mt5_data.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from releat.utils.logging import get_logger\n",
    "from releat.utils.configs.config_builder import load_config\n",
    "from releat.data.pipeline import load_raw_tick_data\n",
    "from releat.data.cleaning import group_tick_data_by_time\n",
    "from releat.data.simple.stats import calc_gradient_feature\n",
    "from releat.data.cleaning import fill_trade_interval\n",
    "from releat.data.transformers import get_transform_params\n",
    "import logging\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "logger = get_logger(__name__, log_level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load feature config and data\n",
    "\n",
    "- For this example, see /agents/t00001/feature_config.py\n",
    "- The load_config function validates configs via pydantic as well as combines all the other config files in the /agents/t00001 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('t00001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the feature group - in this case we want the 5m timeframe\n",
    "feat_group_ind = 1\n",
    "\n",
    "# Index of the feature within the feature group\n",
    "feat_ind = 3\n",
    "\n",
    "feat_group = config.features[feat_group_ind]\n",
    "fc = feat_group.simple_features[feat_ind]\n",
    "\n",
    "# the simple config that defines a single feature (conversion to dict is for printing only)\n",
    "dict(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tick data\n",
    "dt = '2023-06-01'\n",
    "symbol = fc.symbol\n",
    "broker = fc.broker\n",
    "tick_df = load_raw_tick_data(config, broker, symbol, dt)\n",
    "\n",
    "# For this example, reduce sample size so that it runs quickly\n",
    "tick_df = tick_df.head(100_000)\n",
    "\n",
    "# Note that this is a polars dataframe\n",
    "tick_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = group_tick_data_by_time(config, feat_group_ind, tick_df)\n",
    "\n",
    "# Print some summary statistics\n",
    "summary = df_group.agg(\n",
    "    [\n",
    "        pl.col(\"time_msc\").min().alias(\"min_datetime\"),\n",
    "        pl.col(\"time_msc\").max().alias(\"max_datetime\"),\n",
    "        pl.col(\"time_msc\").count().alias(\"num_ticks\"),\n",
    "        pl.col(\"avg_price\").last().alias(\"price\")\n",
    "    ]\n",
    ")\n",
    "summary.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this group by, note that:\n",
    "\n",
    "- the column `time_msc` will be used as the index for building the feature\n",
    "- the column `time_msc` increments in 10s, which is defined as the `trade_timeframe` parameter in `agents/t00001/agent_config.py`\n",
    "- the `min_datetime` and `max_datetime` look forward, i.e. for the timestamp `2023-05-31 00:01:20`, the maximum datetime in that group is `2023-05-31 00:06:14.865`. The time shift so that the feature done after the feature is build, i.e. later the timestamp for this group will be converted to `2023-05-31 00:06:20`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Feature\n",
    "\n",
    "This is mostly taken from the `make_feature` function of `releat/data/pipeline.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_timeframe = fc.timeframe\n",
    "trade_timeframe = config.raw_data.trade_timeframe\n",
    "pip = config.symbol_info[config.symbol_info_index[fc.symbol]].pip\n",
    "\n",
    "# make the gradient feature\n",
    "df = calc_gradient_feature(df_group, fc, pip)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted above, then clean the `time_msc` column by making sure its the correct type and adding a time offset. The timestamp label for each feature should refer to the right boundary, i.e. the gradient feature for `2023-05-31 00:06:20` refers to tick data that happens between `2023-05-31 00:01:20` (inclusive) and `2023-05-31 00:06:20` (excluding this timestamp)\n",
    "\n",
    "We also shift the feature by a trade time offset, which represents the lag or number of seconds that the agent makes a trade after the information is available. For this example, this lag is set to 3s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(pl.col(\"time_msc\").dt.cast_time_unit(\"ns\"))\n",
    "df = df.with_columns(pl.col(\"time_msc\").dt.offset_by(feature_timeframe)).with_columns(\n",
    "        pl.col(\"time_msc\").dt.offset_by(config.raw_data.trade_time_offset),\n",
    "    )\n",
    "df.head(10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill any NAs in the dataset according to the feature config, also fill in any missing\n",
    "# timeframes\n",
    "print(f\"feature set length before fill: {len(df)}\")\n",
    "df = fill_trade_interval(df, trade_timeframe, fc.fillna)\n",
    "print(f\"feature set length after fill: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale and Transform Feature\n",
    "\n",
    "Note that this overwrites any existing scaling parameters in `data/agent/t00001/features/1_5m/3_grad/transforms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The transforms are specified per feature config\n",
    "fc.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [x for x in df.columns if x != \"time_msc\"]\n",
    "feats = df.select(cols).to_numpy()\n",
    "\n",
    "feats_t = get_transform_params(config, feat_group_ind, feat_ind, feats)\n",
    "feats_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Feature\n",
    "\n",
    "For the purposes of visualising, the datasets are roughly joined together. i.e. the filled in dataset has more records than the initial summary, but in this example the differences are small and is ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_t = feats_t[:len(summary),0]\n",
    "summary = summary.to_pandas()\n",
    "summary[\"feature\"] = feats_t\n",
    "summary.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.set_index(\"time_msc\",inplace=True)\n",
    "summary = summary[[\"price\",\"feature\"]]\n",
    "summary.iloc[800:1000].plot(secondary_y='price', figsize=(8, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
